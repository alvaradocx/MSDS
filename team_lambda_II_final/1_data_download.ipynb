{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. ABIDE Data Download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lr_m_Q7PmG-w"
   },
   "source": [
    "ABIDE Dataset Download Script obtained from https://github.com/preprocessed-connectomes-project/abide/blob/master/download_abide_preproc.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code from Github + Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XyORTCcKkUXK"
   },
   "outputs": [],
   "source": [
    "# download_abide_preproc.py\n",
    "#\n",
    "# Author: Daniel Clark, 2015\n",
    "# Updated to python 3 and to support downloading by DX, Cameron Craddock, 2019\n",
    "\n",
    "\"\"\"\n",
    "This script downloads data from the Preprocessed Connetomes Project's\n",
    "ABIDE Preprocessed data release and stores the files in a local\n",
    "directory; users specify derivative, pipeline, strategy, and optionally\n",
    "age ranges, sex, site of interest\n",
    "Usage:\n",
    "    python download_abide_preproc.py -d <derivative> -p <pipeline>\n",
    "                                     -s <strategy> -o <out_dir>\n",
    "                                     [-lt <less_than>] [-gt <greater_than>]\n",
    "                                     [-x <sex>] [-t <site>]\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# Main collect and download function\n",
    "def collect_and_download(derivative, pipeline, strategy, out_dir, less_than, greater_than, site, sex, diagnosis):\n",
    "    \"\"\"\n",
    "    Function to collect and download images from the ABIDE preprocessed\n",
    "    directory on FCP-INDI's S3 bucket\n",
    "    Parameters\n",
    "    ----------\n",
    "    derivative : string\n",
    "        derivative or measure of interest\n",
    "    pipeline : string\n",
    "        pipeline used to process data of interest\n",
    "    strategy : string\n",
    "        noise removal strategy used to process data of interest\n",
    "    out_dir : string\n",
    "        filepath to a local directory to save files to\n",
    "    less_than : float\n",
    "        upper age (years) threshold for participants of interest\n",
    "    greater_than : float\n",
    "        lower age (years) threshold for participants of interest\n",
    "    site : string\n",
    "        acquisition site of interest\n",
    "    sex : string\n",
    "        'M' or 'F' to indicate whether to download male or female data\n",
    "    diagnosis : string\n",
    "        'asd', 'tdc', or 'both' corresponding to the diagnosis of the\n",
    "        participants for whom data should be downloaded\n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "        this function does not return a value; it downloads data from\n",
    "        S3 to a local directory\n",
    "    :param derivative: \n",
    "    :param pipeline: \n",
    "    :param strategy: \n",
    "    :param out_dir: \n",
    "    :param less_than: \n",
    "    :param greater_than: \n",
    "    :param site: \n",
    "    :param sex:\n",
    "    :param diagnosis:\n",
    "    :return: \n",
    "    \"\"\"\n",
    "\n",
    "    # Import packages\n",
    "    import os\n",
    "    import urllib.request as request\n",
    "\n",
    "    # Init variables\n",
    "    mean_fd_thresh = 0.2\n",
    "    s3_prefix = 'https://s3.amazonaws.com/fcp-indi/data/Projects/'\\\n",
    "                'ABIDE_Initiative'\n",
    "    s3_pheno_path = '/'.join([s3_prefix, 'Phenotypic_V1_0b_preprocessed1.csv'])\n",
    "\n",
    "    # Format input arguments to be lower case, if not already\n",
    "    derivative = derivative.lower()\n",
    "    pipeline = pipeline.lower()\n",
    "    strategy = strategy.lower()\n",
    "\n",
    "    # Check derivative for extension\n",
    "    if 'roi' in derivative:\n",
    "        extension = '.1D'\n",
    "    else:\n",
    "        extension = '.nii.gz'\n",
    "\n",
    "    # If output path doesn't exist, create it\n",
    "    if not os.path.exists(out_dir):\n",
    "        print('Could not find {0}, creating now...'.format(out_dir))\n",
    "        os.makedirs(out_dir)\n",
    "\n",
    "    # Load the phenotype file from S3\n",
    "    s3_pheno_file = request.urlopen(s3_pheno_path)\n",
    "    pheno_list = s3_pheno_file.readlines()\n",
    "    print(pheno_list[0])\n",
    "\n",
    "    # Get header indices\n",
    "    header = pheno_list[0].decode().split(',')\n",
    "    try:\n",
    "        site_idx = header.index('SITE_ID')\n",
    "        file_idx = header.index('FILE_ID')\n",
    "        age_idx = header.index('AGE_AT_SCAN')\n",
    "        sex_idx = header.index('SEX')\n",
    "        dx_idx = header.index('DX_GROUP')\n",
    "        mean_fd_idx = header.index('func_mean_fd')\n",
    "    except Exception as exc:\n",
    "        err_msg = 'Unable to extract header information from the pheno file: {0}\\nHeader should have pheno info:' \\\n",
    "                  ' {1}\\nError: {2}'.format(s3_pheno_path, str(header), exc)\n",
    "        raise Exception(err_msg)\n",
    "\n",
    "    # Go through pheno file and build download paths\n",
    "    print('Collecting images of interest...')\n",
    "    s3_paths = []\n",
    "    for pheno_row in pheno_list[1:]:\n",
    "\n",
    "        # Comma separate the row\n",
    "        cs_row = pheno_row.decode().split(',')\n",
    "\n",
    "        try:\n",
    "            # See if it was preprocessed\n",
    "            row_file_id = cs_row[file_idx]\n",
    "            # Read in participant info\n",
    "            row_site = cs_row[site_idx]\n",
    "            row_age = float(cs_row[age_idx])\n",
    "            row_sex = cs_row[sex_idx]\n",
    "            row_dx = cs_row[dx_idx]\n",
    "            row_mean_fd = float(cs_row[mean_fd_idx])\n",
    "        except Exception as e:\n",
    "            err_msg = 'Error extracting info from phenotypic file, skipping...'\n",
    "            print(err_msg)\n",
    "            continue\n",
    "\n",
    "        # If the filename isn't specified, skip\n",
    "        if row_file_id == 'no_filename':\n",
    "            continue\n",
    "        # If mean fd is too large, skip\n",
    "        if row_mean_fd >= mean_fd_thresh:\n",
    "            continue\n",
    "\n",
    "        # Test phenotypic criteria (three if's looks cleaner than one long if)\n",
    "        # Test sex\n",
    "        if (sex == 'M' and row_sex != '1') or (sex == 'F' and row_sex != '2'):\n",
    "            continue\n",
    "\n",
    "        if (diagnosis == 'asd' and row_dx != '1') or (diagnosis == 'tdc' and row_dx != '2'):\n",
    "            continue\n",
    "\n",
    "        # Test site\n",
    "        if site is not None and site.lower() != row_site.lower():\n",
    "            continue\n",
    "        # Test age range\n",
    "        if greater_than < row_age < less_than:\n",
    "            filename = row_file_id + '_' + derivative + extension\n",
    "            s3_path = '/'.join([s3_prefix, 'Outputs', pipeline, strategy, derivative, filename])\n",
    "            print('Adding {0} to download queue...'.format(s3_path))\n",
    "            s3_paths.append(s3_path)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    # And download the items\n",
    "    total_num_files = len(s3_paths)\n",
    "    for path_idx, s3_path in enumerate(s3_paths):\n",
    "        rel_path = s3_path.lstrip(s3_prefix)\n",
    "        download_file = os.path.join(out_dir, rel_path)\n",
    "        download_dir = os.path.dirname(download_file)\n",
    "        if not os.path.exists(download_dir):\n",
    "            os.makedirs(download_dir)\n",
    "        try:\n",
    "            if not os.path.exists(download_file):\n",
    "                print('Retrieving: {0}'.format(download_file))\n",
    "                request.urlretrieve(s3_path, download_file)\n",
    "                print('{0:3f}% percent complete'.format(100*(float(path_idx+1)/total_num_files)))\n",
    "            else:\n",
    "                print('File {0} already exists, skipping...'.format(download_file))\n",
    "        except Exception as exc:\n",
    "            print('There was a problem downloading {0}.\\n Check input arguments and try again.'.format(s3_path))\n",
    "\n",
    "    # Print all done\n",
    "    print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "px7wA8Bkzp9l"
   },
   "source": [
    "The download_abide_preproc.py script allows any user to download outputs from the ABIDE preprocessed data release. The user specifies the desired derivative, pipeline, and noise removal strategy of interest, and the script finds the data on FCP-INDI's S3 bucket, hosted by Amazon Web Services, and downloads the data to a local directory. The script also allows for phenotypic specifications for targeting only the particpants whose information meets the desired criteria; these specifications include: diagnosis (either ASD, TDC, or both), an age range (e.g. particpants between 2 and 30 years of age), sex (male or female), and site (location where the images where acquired from). * Note the script only downloads images where the functional image's mean framewise displacement is less than 0.2.\n",
    "\n",
    "At a minimum, the script needs a specific derivative, pipeline, and strategy to search for.\n",
    "Acceptable derivatives include:\n",
    "- alff (Amplitude of low frequency fluctuations)\n",
    "- degree_binarize (Degree centrality with binarized weighting)\n",
    "- degree_weighted (Degree centrality with correlation weighting)\n",
    "- eigenvector_binarize (Eigenvector centrality with binarized weighting)\n",
    "- eigenvector_weighted (Eigenvector centrality with correlation weighting)\n",
    "- falff (Fractional ALFF)\n",
    "- func_mask (Functional data mask)\n",
    "- func_mean (Mean preprocessed functional image)\n",
    "- func_preproc (Preprocessed functional image)\n",
    "- lfcd (Local functional connectivity density)\n",
    "- reho (Regional homogeneity)\n",
    "- rois_aal (Timeseries extracted from the Automated Anatomical Labeling atlas)\n",
    "- rois_cc200 (\" \" from Cameron Craddock's 200 ROI parcellation atlas)\n",
    "- rois_cc400 (\" \" \" 400 ROI parcellation atlas)\n",
    "- rois_dosenbach160 (\" \" from the Dosenbach160 atlas)\n",
    "- rois_ez (\" \" from the Eickhoff-Zilles atlas)\n",
    "- rois_ho (\" \" from the Harvard-Oxford atlas)\n",
    "- rois_tt (\" \" from the Talaraich and Tournoux atlas)\n",
    "- vmhc (Voxel-mirrored homotopic connectivity)\n",
    "\n",
    "Acceptable pipelines include:\n",
    "- ccs\n",
    "- cpac\n",
    "- dparsf\n",
    "- niak\n",
    "\n",
    "Acceptable strategies include:\n",
    "- filt_global (band-pass filtering and global signal regression)\n",
    "- filt_noglobal (band-pass filtering only)\n",
    "- nofilt_global (global signal regression only)\n",
    "- nofilt_noglobal (neither)\n",
    "\n",
    "For example, to download all particpants across all sites' ReHo images processed using C-PAC, without any frequency filtering or global signal regression:\n",
    "    python download_abide_preproc.py -d reho -p cpac -s nofilt_noglobal -o /path/to/local/download/dir\n",
    "\n",
    "The script will then search for and download the data to the local directory specified with the -o flag.\n",
    "\n",
    "Participants can also be selected based on phenotypic information. For example, to download the same outputs from the previous example, but using only male ASD participants scanned from Caltech between the ages of 2 and 30 years:\n",
    "    python download_abide_preproc.py -a -d reho -p cpac -s nofilt_noglobal -o /path/to/local/download/dir -gt 2 -lt 30 -x M -t Caltech\n",
    "\n",
    "For more information on the ABIDE preprocessed initiative, please check out http://preprocessed-connectomes-project.github.io/abide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Female Subjects with ASD diagnosis between ages of 3-18 from all location sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5K5zxdMKzq94"
   },
   "outputs": [],
   "source": [
    "collect_and_download(derivative = 'func_mean', #(Mean preprocessed functional image)\n",
    "                     pipeline = 'ccs', # preprocessing pipeline\n",
    "                     strategy = 'filt_global', # band-pass filtering and global signal regression\n",
    "                     out_dir = '/project/ds6050-soa2wg/team_lambda_II/',\n",
    "                     less_than = 19, #age range less than \n",
    "                     greater_than =2, #age range greater than\n",
    "                     sex = 'F', \n",
    "                     site = None, #location of the scan, None returns all locations\n",
    "                     diagnosis = 'asd' #whether the person has autism spectrum disorder or not\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Male Subjects with ASD diagnosis between ages of 3-18 from all location sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_and_download(derivative = 'func_mean', #(Mean preprocessed functional image)\n",
    "                     pipeline = 'ccs', # preprocessing piepeline\n",
    "                     strategy = 'filt_global', # band-pass filtering and global signal regression\n",
    "                     out_dir = '/project/ds6050-soa2wg/team_lambda_II/', # output directory\n",
    "                     less_than = 19, #age range less than \n",
    "                     greater_than =2, #age range greater than\n",
    "                     sex = 'M', \n",
    "                     site = None, #location of the scan, None returns all locations\n",
    "                     diagnosis = 'asd' #whether the person has autism spectrum disorder or not\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Male Control Subjects between ages of 3-18 from all location sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5K5zxdMKzq94"
   },
   "outputs": [],
   "source": [
    "collect_and_download(derivative = 'func_mean', #(Mean preprocessed functional image)\n",
    "                     pipeline = 'ccs', # preprocessing pipeline\n",
    "                     strategy = 'filt_global', # band-pass filtering and global signal regression\n",
    "                     out_dir = '/project/ds6050-soa2wg/team_lambda_II/',\n",
    "                     less_than = 19, #age range less than \n",
    "                     greater_than =2, #age range greater than\n",
    "                     sex = 'M', \n",
    "                     site = None, #location of the scan, None returns all locations\n",
    "                     diagnosis = 'tdc' #whether the person has autism spectrum disorder or not\n",
    "                     )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Female Control Subjects between ages of 3-18 from all location sites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collect_and_download(derivative = 'func_mean', #(Mean preprocessed functional image)\n",
    "                     pipeline = 'ccs', #don't know what this means\n",
    "                     strategy = 'filt_global', #don't know what this means either\n",
    "                     out_dir = '/project/ds6050-soa2wg/team_lambda_II/',\n",
    "                     less_than = 19, #age range less than \n",
    "                     greater_than =2, #age range greater than\n",
    "                     sex = 'M', \n",
    "                     site = None, #location of the scan, None returns all locations\n",
    "                     diagnosis = 'tdc' #whether the person has autism spectrum disorder or not\n",
    "                     )"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "ABIDE Preprocessed Download.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
